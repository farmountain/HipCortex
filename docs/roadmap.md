# Roadmap & Future Modules

## Completed
- Modular memory architecture
- Temporal indexer (STM/LTM)
- FSM procedural cache
- Symbolic key-value and graph store
- Multimodal perception adapter
- Vision encoder module
- Reflexion/agent integration stubs
- Initial LLM clients (OpenAI, Claude, Ollama)
- TDD, benchmarks, VS Code dev config

## In Progress / Planned
- Semantic cache/compression
- Persistent world model memory
- Real-time agentic CLI and Web UI
- Expanded open-source LLM connectors (Llama, DeepSeek, etc.)
- Local inference via Ollama or custom backends
- EffortEvaluator & ConfidenceRegulator for collapse resistance metrics
- HypothesisManager and quantized state tree for multi-path reasoning
- Procedural backtracking and fallback logic
- Puzzle benchmark harness for algorithmic planning tasks

## Roadmap Highlights
- **Vision encoder**: Integrate image/embedding modules for visual reasoning.
- **Semantic compression**: Memory-efficient summary/compression for long-term storage.
- **RAG/Notion export**: Retrieval adapters and Notion/PDF exporters implemented.
- **World model memory**: Store agent/environment state and simulate context.
- **Real-time CLI/Web**: Manage, debug, and visualize agentic memory interactively.
- **Collapse metrics**: EffortEvaluator and ConfidenceRegulator measure reasoning fatigue and collapse_score.
- **Puzzle benchmark suite**: Validate complex planning tasks like Tower of Hanoi for regression testing.

---

PRs for new modules and improvements are highly encouraged!
