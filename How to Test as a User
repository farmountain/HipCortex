Here’s a step-by-step plan for you (as an external tester) to validate HipCortex’s core modules and use cases manually—both via the CLI/UI and with simple HTTP/gRPC calls.

---

## 1. Prerequisites & Setup

1. **Install Rust toolchain** (≥ 1.70), Cargo, and (for the GUI) Tauri prerequisites (Node.js, Yarn)
2. **Clone & enter repo**

   ```bash
   git clone https://github.com/farmountain/HipCortex.git
   cd HipCortex
   ```
3. **Fetch dependencies & build**

   ```bash
   cargo build
   scripts/codex_startup.sh   # optional pre-fetch
   ```

---

## 2. Verify Build & Tests

* **Run all unit/integration tests**

  ```bash
  cargo test
  ```
* **Run benchmarks**

  ```bash
  cargo bench
  ```
* **Confirm coverage of key components** (audit\_log, temporal\_indexer, symbolic\_store, procedural\_cache, perception\_adapter) ([github.com][1])

---

## 3. CLI Demo & Core Modules

Usage: cli.exe add --actor <ACTOR> --action <ACTION> --target <TARGET>

---

         ## 1. Using `cargo run`
         
         From your project root:
         
         ```powershell
         cargo run -- add --actor "tester" --action "remember" --target "The Eiffel Tower is in Paris"
         ```
         
         * `--actor`  : who is performing the action (you can put anything, e.g. `"tester"`)
         * `--action` : the verb, e.g. `"remember"`
         * `--target` : the fact or data to store, e.g. `"The Eiffel Tower is in Paris"`
         
         The `--` after `cargo run` tells Cargo “everything that follows is for the binary, not for Cargo itself.”
         
         You should see something like:
         
         ```
         ✔️ Added memory record: tester – remember – “The Eiffel Tower is in Paris”
         ```
         
         ---
         
         ## 2. Directly invoking the built executable
         
         If you’ve already built it once (`cargo build`), you can call the `.exe` directly:
         
         ```powershell
         .\target\debug\cli.exe add --actor tester --action remember --target "The Eiffel Tower is in Paris"
         ```
         
         ---
         
         ## 3. Verify it stored correctly
         
         Once it returns successfully, peek at your default store (`memory.jsonl`):
         
         ```powershell
         Get-Content .\memory.jsonl | Select-Object -Last 3
         ```
         
         You should see a JSON line with your new record.
         
         ---
         
         ## 4. Next steps
         
         Now that `add` works, you can exercise the other commands:
         
         * **Query**:
         
           ```powershell
           cargo run -- query --q "Eiffel Tower"
           ```
         * **Snapshot / Restore**:
         
           ```powershell
           cargo run -- snapshot --output snap.jsonl
           cargo run -- add --actor tester --action temp --target "dummy"
           cargo run -- restore --input snap.jsonl
           ```
         * **Prompt** (reflexion):
         
           ```powershell
           cargo run -- prompt --text "Why is the Eiffel Tower famous?"
           ```
         * **Graph export**:
         
           ```powershell
           cargo run -- graph --output world.json
           ```
         
         Each of those subcommands has its own `--help` you can inspect:
         
         ```powershell
         cargo run -- query --help
         cargo run -- prompt --help
         cargo run -- graph --help
         ```
         
         ---
         
         With that, you’ll be able to continue through your manual tests for Hanoi, multi-agent scenarios, etc., using the correct flag-based syntax.



######################################### Others Tests ######################################################
            Here’s how you can systematically exercise each of the CLI commands from your PowerShell prompt:
            
            ---
            
            ### 1. `add` — add a memory record
            
            1. **Inspect usage**
            
               ```powershell
               cargo run -- add --help
               ```
            2. **Add a new fact**
            
               ```powershell
               cargo run -- add --actor tester --action remember --target "The Merlion is in Singapore" --tags location,landmark
               ```
            3. **Verify it was written** (peek at the store file)
            
               ```powershell
               Get-Content .\memory.jsonl -Tail 5
               ```
            
            ---
            
            ### 2. `query` — search your memories
            
            1. **Inspect usage**
            
               ```powershell
               Get-Content .\memory.jsonl -Tail 5
               cargo run -- query --help
               ```
            2. **Run a full-text query**
            
               ```powershell
               cargo run -- query -q "Singapore"
               ```
            3. **Filter by tag**
            
               ```powershell
               cargo run -- query -q "landmark" --tags landmark
               ```
            
            ---
            
            ### 3. `snapshot` & `restore` — checkpointing your store
            
            1. **Take a snapshot**
            
               ```powershell
               cargo run -- snapshot --output hipcortex-snap.jsonl
               ```
            2. **Add a “bad” record**
            
               ```powershell
               cargo run -- add --actor tester --action remember --target "This should be rolled back" --tags temp
               cargo run -- query -q "rolled back"   # you’ll see it
               ```
            3. **Restore your snapshot**
            
               ```powershell
               cargo run -- restore --input hipcortex-snap.jsonl
               ```
            4. **Confirm rollback**
            
               ```powershell
               cargo run -- query -q "rolled back"   # should return nothing
               ```
            
            ---
            
            ### 4. `prompt` — reflexion with OpenAI
            
            > **Note:** you’ll need your `OPENAI_API_KEY` env var set.
            
            1. **Inspect usage**
            
               ```powershell
              cargo run -- prompt --help
               ```
            2. **Send a question**
            
               ```powershell
              cargo run -- prompt "Why is the Merlion famous?"
               ```
            3. **Verify reflexion stored**
            
               ```powershell
              cargo run -- query -q "Merlion" --tags reflexion
               ```
            
            ---
            
            ### 5. `graph` — export the world model
            
            1. **Inspect usage**
            
               ```powershell
              cargo run -- graph --help
               ```
            2. **Dump to JSON**
            
               ```powershell
              cargo run -- graph --output world-model.json
               ```
            3. **Open & inspect**
            
               ```powershell
            cargo run notepad world-model.json
               ```
            
               • Look for nodes (“Merlion”, “Singapore”) and edges (e.g. `located_in`).
            
            ---
            
            ### 6. Iterating & Cleanup
            
            * **Reset your store** (if you want to start fresh)
            
              ```powershell
             cargo run Remove-Item .\memory.jsonl
              ```
            * **Specify an alternate store** (to test isolation)
            
              ```powershell
             cargo run -- --store test-store.jsonl add --actor tester --action remember --target "Test fact"
             cargo run -- --store test-store.jsonl query -q "Test"
              ```
            
            ---
            
            By running through each of those, you’ll cover:
            
            * **Data entry** (`add`)
            * **Search & filtering** (`query`)
            * **Checkpoint & rollback** (`snapshot`/`restore`)
            * **LLM-based reflexion** (`prompt`)
            * **Graph export** (`graph`)


######################################### Advanced Tests for Tower of Hanoi ######################################################
         Here are some **advanced test scenarios** you can use to stress-test the built-in Tower of Hanoi procedural workflow in HipCortex:
         
         ---
         
         ## A. High-Disk Scalability & Performance
         
         1. **Vary Disk Counts**
         
            ```powershell
            # Test 3, 5, 7, and 10 disks
            for ($n in 3,5,7,10) {
              cargo run -- run-hanoi --disks $n --help   # confirm options
              Measure-Command { cargo run -- run-hanoi --disks $n }
            }
            ```
         
            • Verify that move counts match the theoretical 2ⁿ–1.
            • Record elapsed times and ensure they grow roughly exponentially.
         
         2. **Timeout & Abort**
         
            ```powershell
            # Simulate abort on long runs
            $job = Start-Job { cargo run -- run-hanoi --disks 15 }
            Start-Sleep -Seconds 5
            Stop-Job $job
            ```
         
            • Confirm the FSM transitions into an “aborted” state and logs cleanup steps.
         
         ---
         
         ## B. Intermediate-State Queries
         
         1. **Step-by-Step Execution**
         
            ```powershell
            # Advance one move at a time
            cargo run -- hanoi-step --next     # perform and print the next move
            cargo run -- hanoi-status         # show current peg contents
            ```
         
            • Repeat until completion and validate that no illegal moves ever occur (larger-on-smaller).
         
         2. **Rollback Moves**
         
            ```powershell
            # After 10 moves, roll back 5
            1..10 | ForEach-Object { cargo run -- hanoi-step --next }
            cargo run -- hanoi-step --undo 5
            cargo run -- hanoi-status
            ```
         
            • Ensure the last 5 moves are undone accurately and state consistency is maintained.
         
         ---
         
         ## C. Failure & Edge-Case Injection
         
         1. **Invalid Move Injection**
         
            ```powershell
            # Manually issue an illegal move
            cargo run -- hanoi-force-move --from A --to C --disk 3
            ```
         
            • Expect the system to reject it, log an error in AuditLog, and preserve state.
         
         2. **Corrupted State Recovery**
         
            ```powershell
            # Manually tamper with memory.jsonl (remove a disk move)
            (Get-Content memory.jsonl) | Where-Object { $_ -notmatch "Hanoi" } | Set-Content memory.jsonl
           cargo run -- hanoi-status
            ```
         
            • Verify that when you detect missing/invalid moves, the HypothesisManager proposes a repair or flags a contradiction.
         
         ---
         
         ## D. Multi-Agent “Competition” Scenario
         
         1. **Parallel Solvers**
         
            ```powershell
            # Launch two concurrent solvers on the same store
            Start-Job { cargo run -- run-hanoi --disks 8 }
            Start-Job { cargo run -- run-hanoi --disks 8 }
            ```
         
            • Observe how TemporalIndexer queues traces: ensure moves don’t interleave in a way that breaks disk rules.
            • Check Conflict-Resolution logs for any overlapping writes.
         
         ---
         
         ## E. Persistence & Resume
         
         1. **Snapshot Mid-Solution**
         
            ```powershell
            1..20 | ForEach-Object { cargo run -- hanoi-step --next }
            cargo run -- snapshot --output hanoi-20.jsonl
            # Simulate crash
            cargo run -- hanoi-status  # empty or reset
            cargo run -- restore --input hanoi-20.jsonl
            cargo run -- hanoi-status  # should reflect exactly 20 moves played
            ```
         
            • Ensure you can pause, snapshot, and fully resume the puzzle from an arbitrary point.
         
         ---
         
         ## F. Visualization Export
         
         1. **Graph JSON of Current State**
         
            ```powershell
            cargo run -- hanoi-graph --output hanoi-state.json
            ```
         
            • Confirm the JSON includes nodes for each peg and disk, plus a “next\_move” edge.
            • Load into any graph-viz tool to visually verify peg contents.
         
         ---
         
         By running these scenarios you will cover robustness (invalid inputs, parallel writes), usability (step-wise control, snapshots), performance at scale, and the integration of procedural FSM state with persistent memory and conflict resolution.

######################################### Advanced Tests for Tower of Hanoi ######################################################

---

## 4. Examples Suite

HipCortex ships several `examples/`—run them via Cargo to validate specific APIs:

| Example                     | Command                                             | What to check                                    |
| --------------------------- | --------------------------------------------------- | ------------------------------------------------ |
| `quickstart.rs`             | `cargo run --example quickstart`                    | Minimal programmatic usage: insert/query traces  |
| `world_model_example.rs`    | `cargo run --example world_model_example`           | Persistent world-model CRUD                      |
| `rag_export.rs`             | `cargo run --example rag_export`                    | RAG adapter → PDF/Notion export (inspect output) |
| `plugin_host.rs` *(plugin)* | `cargo run --example plugin_host --features plugin` | Load a simple WASM extension and observe hooks   |

---

## 5. REST API (web-server feature)

1. **Build with the web-server feature**

   ```bash
   cargo run --features web-server -- --port 8080
   ```
2. **Smoke-test endpoints** with `curl` or Postman:

   ```bash
   # Store a trace
   curl -X POST http://localhost:8080/memory/trace \
     -H "Content-Type: application/json" \
     -d '{"text":"Hello agents"}'

   # Query symbols
   curl http://localhost:8080/memory/symbols?q=agentic
   ```
3. Confirm JSON schema matches `docs/data_model.md` and operations align with `docs/architecture.md` ([github.com][1]).

---

## 6. GUI (Tauri desktop client)

1. **Build & launch**

   ```bash
   cargo tauri dev --features gui
   ```
2. **Walk through the UI**:

   * **Visualize world model** in real time
   * **Inspect trace logs** and graph views (symbolic store)
   * **Trigger procedural workflows** via buttons

---

## 7. gRPC & Protocol Adapters

1. **Inspect `proto/` definitions** and generate stubs (e.g., with `tonic-build`).
2. **Run the CLI demo or web-server** with gRPC enabled.
3. **Use a gRPC client** (e.g., BloomRPC) to:

   * Call `StoreTrace(…)`
   * Call `QuerySymbols(…)`
4. Validate round-trip requests/responses match the proto spec.

---

## 8. Edge & WASM Plugin

* **Compile for WebAssembly**

  ```bash
  cargo build --target wasm32-unknown-unknown --features plugin
  ```
* **Run the `plugin_host` example** to confirm the `PluginHost` API loads and invokes your `.wasm` module.

---

## 9. Smart-Glasses / Multimodal Tests

* **Use fixture scripts** in `fixtures/` and tests in `tests/multimodal_perception_tests.rs` to confirm image→embedding conversions.
* **Manually feed an image** via the CLI demo (if supported) or by sending a base64 payload to the REST endpoint.

---

## 10. Observability & Metrics

* **Enable logging** (set `RUST_LOG=debug`) and confirm timeline traces, FSM state transitions, and confidence/eﬀort metrics appear in stdout or in a log file.
* **Inspect benchmarks** for temporal decay and semantic compression performance.

---

### Summary

By following these steps—from cloning through CLI, examples, REST/gRPC, GUI, and plugin tests—you’ll systematically validate each HipCortex module and its intended use cases. This approach ensures you cover:

* **Persistence & Retrieval** (PerceptionAdapter, TemporalIndexer, SymbolicStore)
* **Procedural Logic** (FSM cache, puzzle benchmarks)
* **Reasoning Loops** (AureusBridge, HypothesisManager)
* **Integration** (REST/gRPC, WASM, Tauri GUI)
* **Multimodal** (vision encoder, RAG export)

Feel free to adapt or extend these manual tests as new features land.

[1]: https://github.com/farmountain/HipCortex "GitHub - farmountain/HipCortex: LLM AI Memory system"



Here are some **advanced use-case tests** you can tack onto the end of your manual test plan:

---

## 11. Advanced Use-Case Testing

### 11.1 Multi-Agent Orchestration Simulation

* **Goal**: Validate HipCortex’s memory & reasoning under a chain of collaborating agents (e.g., OpenManus + HipCortex).
* **Steps**:

  1. Spin up two processes: one running HipCortex’s REST API (`--port 8080`), another emulating a simple “agent” that calls `POST /memory/trace` → receives retrieved context → acts → writes back a new trace.
  2. Write a shell script or tiny Python loop that alternates these calls for 50 iterations, passing each agent’s trace as the next input.
  3. After completion, inspect the TemporalIndexer and HypothesisManager logs to ensure:

     * No context drift (each agent picks up the right latest context).
     * HypothesisManager maintains a bounded set of active threads.

### 11.2 Chain-of-Thought Consistency & Contradiction Detection

* **Goal**: Stress-test the symbolic contradiction detection on long CoT sequences.
* **Steps**:

  1. Craft a scripted sequence of facts with a built-in contradiction (e.g., “A is taller than B”, later “B is taller than A”).
  2. Feed these via the CLI:

     ```text
     > remember "A is taller than B"
     > remember "B is taller than A"
     ```
  3. Expect the system to:

     * Flag a conflict in the AuditLog.
     * Auto-resolve or prompt (based on config) via the HypothesisManager.

### 11.3 Semantic Compression & Retrieval Latency Benchmark

* **Goal**: Measure impact of semantic compression on retrieval speed/accuracy.
* **Steps**:

  1. Generate 10,000 synthetic “reasoning traces” using the `quickstart` example in a loop.
  2. Run two retrievals of a semantically similar query—one with compression enabled, one disabled:

     ```bash
     RUST_LOG=debug cargo run --example quickstart -- --compress on
     RUST_LOG=debug cargo run --example quickstart -- --compress off
     ```
  3. Compare wall-clock times and inspect similarity scores in logs.

### 11.4 Long-Term Memory Recall & Decay Testing

* **Goal**: Ensure temporal decay rules correctly expire old memories.
* **Steps**:

  1. Insert a fact with an artificially back-dated timestamp (use direct DB write or modify in-memory trace timestamp).
  2. Trigger a retrieval query and confirm that, once past the decay threshold (e.g., 30 days), the fact is no longer returned by TemporalIndexer.

### 11.5 Real-World “Travel Itinerary” RAG Workflow

* **Goal**: Validate the RAG export & multi-modal pipeline in a realistic scenario.
* **Steps**:

  1. Run the `rag_export` example with a prompt like:

     ```bash
     cargo run --example rag_export -- \
       --prompt "Plan a 3-day Singapore itinerary for a foodie" \
       --output plan.pdf
     ```
  2. Inspect the PDF/Notion export for:

     * Correct embedded location images.
     * Consistency between retrieved travel facts and generated itinerary steps.

### 11.6 WASM Plugin Hot-Swap under Load

* **Goal**: Ensure plugin isolation and safe hot-reload.
* **Steps**:

  1. Launch the `plugin_host` example and point it at a “monitoring” WASM plugin.
  2. In rapid succession (100+ times), swap out the `.wasm` binary on disk and invoke the plugin API.
  3. Confirm no host crashes, and that each version of the plugin responds according to its own embedded logic.

### 11.7 gRPC Streaming & Back-Pressure Handling

* **Goal**: Test gRPC stream memory trace ingestion under high throughput.
* **Steps**:

  1. Use a gRPC client to open a `StreamTraces` bi-directional call.
  2. In a tight loop, send >1,000 `StoreTrace` messages and intersperse `QuerySymbols` calls.
  3. Watch for client/server errors, buffer overflows, or unexpected delays; verify HipCortex logs back-pressure warnings when queue thresholds are hit.

### 11.8 GUI Stress Test

* **Goal**: Push the Tauri client UI with large graph visualizations.
* **Steps**:

  1. Load a JSON dump of 5,000 symbolic nodes (from `tests/large_graph.json`) via the GUI’s import feature.
  2. Interact with pan/zoom and node-click handlers.
  3. Confirm UI remains responsive and doesn’t leak memory (monitor via devtools).

---

With these advanced scenarios you’ll cover:

* **Multi-agent chaining** and context hand-offs
* **Formal logic** & conflict resolution
* **Performance & scalability** of compression, decay, and streaming
* **Realistic RAG** and multimodal workflows
* **Plugin robustness** under hot-swap and load
* **UI resilience** with large-scale graphs

Feel free to adapt thresholds or iterate on scripts—these tests will help you uncover edge-case bugs before rolling HipCortex into production.

