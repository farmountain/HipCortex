Here’s a step-by-step plan for you (as an external tester) to validate HipCortex’s core modules and use cases manually—both via the CLI/UI and with simple HTTP/gRPC calls.

---

## 1. Prerequisites & Setup

1. **Install Rust toolchain** (≥ 1.70), Cargo, and (for the GUI) Tauri prerequisites (Node.js, Yarn)
2. **Clone & enter repo**

   ```bash
   git clone https://github.com/farmountain/HipCortex.git
   cd HipCortex
   ```
3. **Fetch dependencies & build**

   ```bash
   cargo build
   scripts/codex_startup.sh   # optional pre-fetch
   ```

---

## 2. Verify Build & Tests

* **Run all unit/integration tests**

  ```bash
  cargo test
  ```
* **Run benchmarks**

  ```bash
  cargo bench
  ```
* **Confirm coverage of key components** (audit\_log, temporal\_indexer, symbolic\_store, procedural\_cache, perception\_adapter) ([github.com][1])

---

## 3. CLI Demo & Core Modules

1. **Launch the built-in CLI demo**

   ```bash
   cargo run
   ```

   * You should see a simple REPL that logs a sample “reasoning trace” via the PerceptionAdapter → TemporalIndexer → SymbolicStore ([github.com][1]).

2. **Exercise key commands**:

   * **Store a new fact**

     ```text
     > remember “The Eiffel Tower is in Paris”
     ```
   * **Query symbols**

     ```text
     > lookup “Eiffel Tower”
     ```
   * **Advance a procedural workflow** (e.g., Tower of Hanoi example)

---

## 4. Examples Suite

HipCortex ships several `examples/`—run them via Cargo to validate specific APIs:

| Example                     | Command                                             | What to check                                    |
| --------------------------- | --------------------------------------------------- | ------------------------------------------------ |
| `quickstart.rs`             | `cargo run --example quickstart`                    | Minimal programmatic usage: insert/query traces  |
| `world_model_example.rs`    | `cargo run --example world_model_example`           | Persistent world-model CRUD                      |
| `rag_export.rs`             | `cargo run --example rag_export`                    | RAG adapter → PDF/Notion export (inspect output) |
| `plugin_host.rs` *(plugin)* | `cargo run --example plugin_host --features plugin` | Load a simple WASM extension and observe hooks   |

---

## 5. REST API (web-server feature)

1. **Build with the web-server feature**

   ```bash
   cargo run --features web-server -- --port 8080
   ```
2. **Smoke-test endpoints** with `curl` or Postman:

   ```bash
   # Store a trace
   curl -X POST http://localhost:8080/memory/trace \
     -H "Content-Type: application/json" \
     -d '{"text":"Hello agents"}'

   # Query symbols
   curl http://localhost:8080/memory/symbols?q=agentic
   ```
3. Confirm JSON schema matches `docs/data_model.md` and operations align with `docs/architecture.md` ([github.com][1]).

---

## 6. GUI (Tauri desktop client)

1. **Build & launch**

   ```bash
   cargo tauri dev --features gui
   ```
2. **Walk through the UI**:

   * **Visualize world model** in real time
   * **Inspect trace logs** and graph views (symbolic store)
   * **Trigger procedural workflows** via buttons

---

## 7. gRPC & Protocol Adapters

1. **Inspect `proto/` definitions** and generate stubs (e.g., with `tonic-build`).
2. **Run the CLI demo or web-server** with gRPC enabled.
3. **Use a gRPC client** (e.g., BloomRPC) to:

   * Call `StoreTrace(…)`
   * Call `QuerySymbols(…)`
4. Validate round-trip requests/responses match the proto spec.

---

## 8. Edge & WASM Plugin

* **Compile for WebAssembly**

  ```bash
  cargo build --target wasm32-unknown-unknown --features plugin
  ```
* **Run the `plugin_host` example** to confirm the `PluginHost` API loads and invokes your `.wasm` module.

---

## 9. Smart-Glasses / Multimodal Tests

* **Use fixture scripts** in `fixtures/` and tests in `tests/multimodal_perception_tests.rs` to confirm image→embedding conversions.
* **Manually feed an image** via the CLI demo (if supported) or by sending a base64 payload to the REST endpoint.

---

## 10. Observability & Metrics

* **Enable logging** (set `RUST_LOG=debug`) and confirm timeline traces, FSM state transitions, and confidence/eﬀort metrics appear in stdout or in a log file.
* **Inspect benchmarks** for temporal decay and semantic compression performance.

---

### Summary

By following these steps—from cloning through CLI, examples, REST/gRPC, GUI, and plugin tests—you’ll systematically validate each HipCortex module and its intended use cases. This approach ensures you cover:

* **Persistence & Retrieval** (PerceptionAdapter, TemporalIndexer, SymbolicStore)
* **Procedural Logic** (FSM cache, puzzle benchmarks)
* **Reasoning Loops** (AureusBridge, HypothesisManager)
* **Integration** (REST/gRPC, WASM, Tauri GUI)
* **Multimodal** (vision encoder, RAG export)

Feel free to adapt or extend these manual tests as new features land.

[1]: https://github.com/farmountain/HipCortex "GitHub - farmountain/HipCortex: LLM AI Memory system"



Here are some **advanced use-case tests** you can tack onto the end of your manual test plan:

---

## 11. Advanced Use-Case Testing

### 11.1 Multi-Agent Orchestration Simulation

* **Goal**: Validate HipCortex’s memory & reasoning under a chain of collaborating agents (e.g., OpenManus + HipCortex).
* **Steps**:

  1. Spin up two processes: one running HipCortex’s REST API (`--port 8080`), another emulating a simple “agent” that calls `POST /memory/trace` → receives retrieved context → acts → writes back a new trace.
  2. Write a shell script or tiny Python loop that alternates these calls for 50 iterations, passing each agent’s trace as the next input.
  3. After completion, inspect the TemporalIndexer and HypothesisManager logs to ensure:

     * No context drift (each agent picks up the right latest context).
     * HypothesisManager maintains a bounded set of active threads.

### 11.2 Chain-of-Thought Consistency & Contradiction Detection

* **Goal**: Stress-test the symbolic contradiction detection on long CoT sequences.
* **Steps**:

  1. Craft a scripted sequence of facts with a built-in contradiction (e.g., “A is taller than B”, later “B is taller than A”).
  2. Feed these via the CLI:

     ```text
     > remember "A is taller than B"
     > remember "B is taller than A"
     ```
  3. Expect the system to:

     * Flag a conflict in the AuditLog.
     * Auto-resolve or prompt (based on config) via the HypothesisManager.

### 11.3 Semantic Compression & Retrieval Latency Benchmark

* **Goal**: Measure impact of semantic compression on retrieval speed/accuracy.
* **Steps**:

  1. Generate 10,000 synthetic “reasoning traces” using the `quickstart` example in a loop.
  2. Run two retrievals of a semantically similar query—one with compression enabled, one disabled:

     ```bash
     RUST_LOG=debug cargo run --example quickstart -- --compress on
     RUST_LOG=debug cargo run --example quickstart -- --compress off
     ```
  3. Compare wall-clock times and inspect similarity scores in logs.

### 11.4 Long-Term Memory Recall & Decay Testing

* **Goal**: Ensure temporal decay rules correctly expire old memories.
* **Steps**:

  1. Insert a fact with an artificially back-dated timestamp (use direct DB write or modify in-memory trace timestamp).
  2. Trigger a retrieval query and confirm that, once past the decay threshold (e.g., 30 days), the fact is no longer returned by TemporalIndexer.

### 11.5 Real-World “Travel Itinerary” RAG Workflow

* **Goal**: Validate the RAG export & multi-modal pipeline in a realistic scenario.
* **Steps**:

  1. Run the `rag_export` example with a prompt like:

     ```bash
     cargo run --example rag_export -- \
       --prompt "Plan a 3-day Singapore itinerary for a foodie" \
       --output plan.pdf
     ```
  2. Inspect the PDF/Notion export for:

     * Correct embedded location images.
     * Consistency between retrieved travel facts and generated itinerary steps.

### 11.6 WASM Plugin Hot-Swap under Load

* **Goal**: Ensure plugin isolation and safe hot-reload.
* **Steps**:

  1. Launch the `plugin_host` example and point it at a “monitoring” WASM plugin.
  2. In rapid succession (100+ times), swap out the `.wasm` binary on disk and invoke the plugin API.
  3. Confirm no host crashes, and that each version of the plugin responds according to its own embedded logic.

### 11.7 gRPC Streaming & Back-Pressure Handling

* **Goal**: Test gRPC stream memory trace ingestion under high throughput.
* **Steps**:

  1. Use a gRPC client to open a `StreamTraces` bi-directional call.
  2. In a tight loop, send >1,000 `StoreTrace` messages and intersperse `QuerySymbols` calls.
  3. Watch for client/server errors, buffer overflows, or unexpected delays; verify HipCortex logs back-pressure warnings when queue thresholds are hit.

### 11.8 GUI Stress Test

* **Goal**: Push the Tauri client UI with large graph visualizations.
* **Steps**:

  1. Load a JSON dump of 5,000 symbolic nodes (from `tests/large_graph.json`) via the GUI’s import feature.
  2. Interact with pan/zoom and node-click handlers.
  3. Confirm UI remains responsive and doesn’t leak memory (monitor via devtools).

---

With these advanced scenarios you’ll cover:

* **Multi-agent chaining** and context hand-offs
* **Formal logic** & conflict resolution
* **Performance & scalability** of compression, decay, and streaming
* **Realistic RAG** and multimodal workflows
* **Plugin robustness** under hot-swap and load
* **UI resilience** with large-scale graphs

Feel free to adapt thresholds or iterate on scripts—these tests will help you uncover edge-case bugs before rolling HipCortex into production.

